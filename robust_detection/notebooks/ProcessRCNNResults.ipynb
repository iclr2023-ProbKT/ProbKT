{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f15badab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmoldenhof\u001b[0m (\u001b[33mrobust-detection\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/moldenho/Projects/ProbKT/robust_detection/notebooks/wandb/run-20220909_140904-1gklsnt4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/robust-detection/ProbKT-robust_detection_notebooks/runs/1gklsnt4\" target=\"_blank\">skilled-river-5</a></strong> to <a href=\"https://wandb.ai/robust-detection/ProbKT-robust_detection_notebooks\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "from robust_detection.wandb_config import ENTITY\n",
    "from robust_detection.models.rcnn import RCNN\n",
    "from robust_detection.data_utils.rcnn_data_utils import Objects_RCNN\n",
    "#from torchmetrics.detection.map import MeanAveragePrecision\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7610b047",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = 0\n",
    "api = wandb.Api()\n",
    "\n",
    "results = {}\n",
    "\n",
    "sweep_dict = {\"y9tovbu0\":RCNN}\n",
    "model_names = [\"RCNN (Range DPL)\"]\n",
    "\n",
    "\n",
    "#data_dict = {\"MMSynthetic\":SyntheticMMDataModule, \"Pendulum\":PendulumDataModule, \"CV\":CVDataModule}\n",
    "#data_dict = {\"molecules/mol_labels/\":Objects_RCNN}#, \"mnist/alldigits_2\":MNISTCountDataModule,  \"mnist/alldigits_5\":MNISTCountDataModule} #, \\\n",
    "            #\"mnist/alldigits_large\":MNISTCountDataModule, \"mnist/alldigits_2_large\":MNISTCountDataModule,  \"mnist/alldigits_5_large\":MNISTCountDataModule,}\n",
    "#data_dict = {\"mnist/alldigits_5/\":Objects_RCNN}#, \"mnist/alldigits_2\":MNISTCountDataModule,  \"mnist/alldigits_5\":MNISTCountDataModule} #, \\\n",
    "            #\"mnist/alldigits_large\":MNISTCountDataModule\n",
    "data_dict = {\"clevr/clevr_skip_cube\":Objects_RCNN}\n",
    "\n",
    "fold_name = \"fold\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24627f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1170b9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Run robust-detection/object_detection/4syov2kr (finished)>, <Run robust-detection/object_detection/9kg0ubbn (finished)>, <Run robust-detection/object_detection/uusrvgm5 (finished)>, <Run robust-detection/object_detection/6ihgego5 (finished)>, <Run robust-detection/object_detection/ixpng3ru (finished)>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moldenho/miniconda3/envs/conda_poetry/lib/python3.8/site-packages/pytorch_lightning/loops/utilities.py:91: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d8d76729024d42b94b761e589f2bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996\n",
      "{'map': tensor(0.9621), 'map_50': tensor(0.9988), 'map_75': tensor(0.9975), 'map_small': tensor(-1.), 'map_medium': tensor(0.9621), 'map_large': tensor(-1.), 'mar_1': tensor(0.8455), 'mar_10': tensor(0.9761), 'mar_100': tensor(0.9761), 'mar_small': tensor(-1.), 'mar_medium': tensor(0.9761), 'mar_large': tensor(-1.), 'map_per_class': tensor(-1.), 'mar_100_per_class': tensor(-1.)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c068d7bab0948ea939afd775b46fa44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994\n",
      "{'map': tensor(0.9166), 'map_50': tensor(0.9975), 'map_75': tensor(0.9975), 'map_small': tensor(-1.), 'map_medium': tensor(0.9166), 'map_large': tensor(-1.), 'mar_1': tensor(0.8155), 'mar_10': tensor(0.9425), 'mar_100': tensor(0.9425), 'mar_small': tensor(-1.), 'mar_medium': tensor(0.9425), 'mar_large': tensor(-1.), 'map_per_class': tensor(-1.), 'mar_100_per_class': tensor(-1.)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4afeb8ff4553495b8f6e262ae8788827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994\n",
      "{'map': tensor(0.9353), 'map_50': tensor(1.0000), 'map_75': tensor(0.9988), 'map_small': tensor(-1.), 'map_medium': tensor(0.9353), 'map_large': tensor(-1.), 'mar_1': tensor(0.8292), 'mar_10': tensor(0.9580), 'mar_100': tensor(0.9580), 'mar_small': tensor(-1.), 'mar_medium': tensor(0.9580), 'mar_large': tensor(-1.), 'map_per_class': tensor(-1.), 'mar_100_per_class': tensor(-1.)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "502382b615404e469b535b68f1f2fe49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.992\n",
      "{'map': tensor(0.8579), 'map_50': tensor(0.9975), 'map_75': tensor(0.9975), 'map_small': tensor(-1.), 'map_medium': tensor(0.8579), 'map_large': tensor(-1.), 'mar_1': tensor(0.7667), 'mar_10': tensor(0.8864), 'mar_100': tensor(0.8864), 'mar_small': tensor(-1.), 'mar_medium': tensor(0.8864), 'mar_large': tensor(-1.), 'map_per_class': tensor(-1.), 'mar_100_per_class': tensor(-1.)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e589d66290e2425993729a0f5533dce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.992\n",
      "{'map': tensor(0.9379), 'map_50': tensor(0.9975), 'map_75': tensor(0.9975), 'map_small': tensor(-1.), 'map_medium': tensor(0.9379), 'map_large': tensor(-1.), 'mar_1': tensor(0.8314), 'mar_10': tensor(0.9605), 'mar_100': tensor(0.9605), 'mar_small': tensor(-1.), 'mar_medium': tensor(0.9605), 'mar_large': tensor(-1.), 'map_per_class': tensor(-1.), 'mar_100_per_class': tensor(-1.)}\n",
      "{'Model': 'RCNN (Range DPL) (Acc)', 'Type': 'In-distribution', 'clevr/clevr_skip_cube': '$ 0.994\\\\pm0.001 $', 'clevr/clevr_skip_cube mAP': '$ 0.922\\\\pm0.035 $'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3587003/3439516838.py:87: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd_dict_acc,ignore_index =True)\n",
      "/home/moldenho/miniconda3/envs/conda_poetry/lib/python3.8/site-packages/pytorch_lightning/loops/utilities.py:91: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/moldenho/Projects/ProbKT/robust_detection/../generate_data/clevr/clevr_skip_cube/test_ood/images/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(logger \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ood:\n\u001b[0;32m---> 47\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_ood_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     preds \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mpredict(model, dataset\u001b[38;5;241m.\u001b[39mtest_dataloader())\n",
      "File \u001b[0;32m~/miniconda3/envs/conda_poetry/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1023\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;124;03mRun inference on your data.\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;124;03mThis will call the model forward function to compute predictions. Useful to perform distributed\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;124;03m    Returns a list of dictionaries, one for each provided dataloader containing their respective predictions.\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module\n\u001b[0;32m-> 1023\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/conda_poetry/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:721\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 721\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;66;03m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m~/miniconda3/envs/conda_poetry/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1070\u001b[0m, in \u001b[0;36mTrainer._predict_impl\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_ckpt_path(\n\u001b[1;32m   1065\u001b[0m     ckpt_path, model_provided\u001b[38;5;241m=\u001b[39mmodel_provided, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m )\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predicted_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt_path  \u001b[38;5;66;03m# TODO: remove in v1.8\u001b[39;00m\n\u001b[0;32m-> 1070\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/conda_poetry/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1234\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mrestore_training_state()\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mresume_end()\n\u001b[0;32m-> 1234\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1236\u001b[0m log\u001b[38;5;241m.\u001b[39mdetail(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_teardown()\n",
      "File \u001b[0;32m~/miniconda3/envs/conda_poetry/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1320\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_evaluate()\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[0;32m-> 1320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_train()\n",
      "File \u001b[0;32m~/miniconda3/envs/conda_poetry/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1375\u001b[0m, in \u001b[0;36mTrainer._run_predict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[_PREDICT_OUTPUT]:\n\u001b[0;32m-> 1375\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_predict_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;66;03m# reset trainer on this loop and all child loops in case user connected a custom loop\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_loop\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/conda_poetry/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1980\u001b[0m, in \u001b[0;36mTrainer.reset_predict_dataloader\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m   1978\u001b[0m enable_prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlimit_predict_batches \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1979\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source\u001b[38;5;241m.\u001b[39mis_defined() \u001b[38;5;129;01mand\u001b[39;00m enable_prediction:\n\u001b[0;32m-> 1980\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_predict_batches, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_dataloaders \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_connector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reset_eval_dataloader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mRunningStage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPREDICTING\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpl_module\u001b[49m\n\u001b[1;32m   1982\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/conda_poetry/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:404\u001b[0m, in \u001b[0;36mDataConnector._reset_eval_dataloader\u001b[0;34m(self, mode, model)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dataloaders) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, dataloader \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloaders):\n\u001b[1;32m    403\u001b[0m         orig_num_batches \u001b[38;5;241m=\u001b[39m num_batches \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 404\u001b[0m             \u001b[38;5;28mlen\u001b[39m(dataloader) \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mhas_len_all_ranks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    405\u001b[0m         )\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_worker_check(dataloader, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;241m.\u001b[39mdataloader_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_dataloader \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;66;03m# percent or num_steps\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/conda_poetry/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:123\u001b[0m, in \u001b[0;36mhas_len_all_ranks\u001b[0;34m(dataloader, training_type, model)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m\"\"\"Checks if a given Dataloader has ``__len__`` method implemented i.e. if it is a finite dataloader or\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03minfinite dataloader.\"\"\"\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 123\u001b[0m     local_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     total_length \u001b[38;5;241m=\u001b[39m training_type\u001b[38;5;241m.\u001b[39mreduce(torch\u001b[38;5;241m.\u001b[39mtensor(local_length)\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice), reduce_op\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m total_length \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/conda_poetry/lib/python3.8/site-packages/torch/utils/data/dataloader.py:413\u001b[0m, in \u001b[0;36mDataLoader.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m length\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_sampler\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/conda_poetry/lib/python3.8/site-packages/pytorch_lightning/overrides/distributed.py:139\u001b[0m, in \u001b[0;36mIndexBatchSamplerWrapper.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sampler\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/conda_poetry/lib/python3.8/site-packages/torch/utils/data/sampler.py:242\u001b[0m, in \u001b[0;36mBatchSampler.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size\n",
      "File \u001b[0;32m~/miniconda3/envs/conda_poetry/lib/python3.8/site-packages/torch/utils/data/sampler.py:69\u001b[0m, in \u001b[0;36mSequentialSampler.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_source\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/ProbKT/robust_detection/data_utils/rcnn_data_utils.py:301\u001b[0m, in \u001b[0;36mObjects_Detection_Dataset.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m([name \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/images/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m])\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/moldenho/Projects/ProbKT/robust_detection/../generate_data/clevr/clevr_skip_cube/test_ood/images/'"
     ]
    }
   ],
   "source": [
    "for i_mod, sweep_name in enumerate(sweep_dict.keys()):\n",
    "\n",
    "    pd_dict_acc = {\"Model\":model_names[i_mod] + \" (Acc)\"}\n",
    "    pd_dict_map = {\"Model\":model_names[i_mod] + \" (mAP)\"}\n",
    "\n",
    "\n",
    "    #model_cls = sweep_dict[sweep_names]\n",
    "    #sweep_runs = []\n",
    "    #for sweep_name in sweep_names:\n",
    "    #    sweep_runs += api.sweep(f\"{ENTITY}/object_detection/{sweep_name}\").runs\n",
    "    model_cls = sweep_dict[sweep_name]\n",
    "    sweep = api.sweep(f\"{ENTITY}/object_detection/{sweep_name}\")\n",
    "    sweep_runs = []\n",
    "    sweep_runs += api.sweep(f\"{ENTITY}/object_detection/{sweep_name}\").runs\n",
    "    print(sweep_runs)\n",
    "    for ood in [False,True]:\n",
    "\n",
    "        pd_dict_acc[\"Type\"] = \"OOD\" if ood else \"In-distribution\"\n",
    "        pd_dict_map[\"Type\"] = \"OOD\" if ood else \"In-distribution\"\n",
    "\n",
    "        \n",
    "        for data_key in data_dict.keys():\n",
    "\n",
    "            best_runs = []\n",
    "            for fold in [0,1,2,3,4]:\n",
    "                #runs_fold = [r for r in sweep_runs if (r.config.get(fold_name)==fold) and (r.config.get(\"target_data_path\")==data_key)]\n",
    "                runs_fold = [r for r in sweep_runs if (r.config.get(fold_name)==fold)]\n",
    "                runs_fold_sorted = sorted(runs_fold,key = lambda run: run.summary.get(\"restored_val_acc\"), reverse = True)\n",
    "                best_runs.append(runs_fold_sorted[0])\n",
    "\n",
    "            accuracies = []\n",
    "            mAPs = []\n",
    "            for run in best_runs:\n",
    "                fname = [f.name for f in run.files() if \"ckpt\" in f.name][0]\n",
    "                run.file(fname).download(replace = True, root = \".\")\n",
    "                model = model_cls.load_from_checkpoint(fname)\n",
    "                os.remove(fname)\n",
    "\n",
    "                hparams = dict(model.hparams)\n",
    "                hparams[\"re_train\"] = False\n",
    "                hparams[\"data_path\"]= data_key\n",
    "                dataset = data_dict[data_key](**hparams)\n",
    "                dataset.prepare_data()\n",
    "                trainer = pl.Trainer(logger = False, gpus = 1)\n",
    "\n",
    "                if ood:\n",
    "                    preds = trainer.predict(model, dataset.test_ood_dataloader())\n",
    "                else:\n",
    "                    preds = trainer.predict(model, dataset.test_dataloader())\n",
    "                \n",
    "                Y = []\n",
    "                Y_hat = []\n",
    "                map_metric = MeanAveragePrecision()\n",
    "                for pred in preds:\n",
    "                    Y += pred[\"targets\"]\n",
    "                    Y_hat += pred[\"preds\"]\n",
    "                    \n",
    "                    pred_map = [dict(boxes=pred[\"boxes\"][i],scores=pred[\"scores\"][i],labels=pred[\"preds\"][i]) for i in range(len(pred[\"targets\"]))]\n",
    "                    target_map = [dict(boxes=pred[\"boxes_true\"][i],labels=pred[\"targets\"][i]) for i in range(len(pred[\"targets\"]))]\n",
    "                    map_metric.update(pred_map,target_map)\n",
    "                \n",
    "                mAP = map_metric.compute()\n",
    "                accuracy = np.array([torch.equal(Y[i].sort()[0],Y_hat[i].sort()[0]) for i in range(len(Y))]).mean()\n",
    "                print(accuracy)\n",
    "                print(mAP)\n",
    "\n",
    "                accuracies.append(accuracy)\n",
    "                mAPs.append(mAP[\"map\"])\n",
    "\n",
    "            accuracies = np.array(accuracies)\n",
    "            acc_mu = accuracies.mean()\n",
    "            acc_std = accuracies.std()\n",
    "            \n",
    "            mAPs = np.array(mAPs)\n",
    "            map_mu = mAPs.mean()\n",
    "            map_std = mAPs.std()\n",
    "\n",
    "            acc_str = \"$ \" + str(acc_mu.round(3))+ \"\\pm\" +str(acc_std.round(3)) +\" $\"\n",
    "            map_str = \"$ \" + str(map_mu.round(3))+ \"\\pm\" +str(map_std.round(3)) +\" $\"\n",
    "\n",
    "\n",
    "            pd_dict_acc[data_key] = acc_str\n",
    "            pd_dict_acc[data_key + \" mAP\"] = map_str\n",
    "\n",
    "            print(pd_dict_acc)\n",
    "\n",
    "        df = df.append(pd_dict_acc,ignore_index =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e087ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      "                 Model &            Type & clevr/clevr_skip_cube & clevr/clevr_skip_cube mAP \\\\\n",
      "\\midrule\n",
      "RCNN (Range DPL) (Acc) & In-distribution &     $ 0.994\\pm0.001 $ &         $ 0.922\\pm0.035 $ \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3587003/3650743742.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(df.loc[df.Model.str.contains(\"Acc\")].to_latex(escape = False,index= False))\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[df.Model.str.contains(\"Acc\")].to_latex(escape = False,index= False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4964e37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
