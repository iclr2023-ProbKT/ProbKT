{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f15badab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmoldenhof\u001b[0m (\u001b[33mrobust-detection\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/moldenho/Projects/ProbKT/robust_detection/notebooks/wandb/run-20220908_160905-3mqbuoqa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/robust-detection/ProbKT-robust_detection_notebooks/runs/3mqbuoqa\" target=\"_blank\">tough-music-1</a></strong> to <a href=\"https://wandb.ai/robust-detection/ProbKT-robust_detection_notebooks\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchmetrics.detection.map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrobust_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrcnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RCNN\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrobust_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrcnn_data_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Objects_RCNN\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdetection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmap\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MeanAveragePrecision\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchmetrics.detection.map'"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from robust_detection.wandb_config import ENTITY\n",
    "from robust_detection.models.rcnn import RCNN\n",
    "from robust_detection.data_utils.rcnn_data_utils import Objects_RCNN\n",
    "#from torchmetrics.detection.map import MeanAveragePrecision\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7610b047",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = 0\n",
    "api = wandb.Api()\n",
    "\n",
    "results = {}\n",
    "\n",
    "sweep_dict = {\"abdv8kfl\":RCNN}\n",
    "model_names = [\"RCNN (DPL track)\"]\n",
    "\n",
    "\n",
    "#data_dict = {\"MMSynthetic\":SyntheticMMDataModule, \"Pendulum\":PendulumDataModule, \"CV\":CVDataModule}\n",
    "#data_dict = {\"molecules/mol_labels/\":Objects_RCNN}#, \"mnist/alldigits_2\":MNISTCountDataModule,  \"mnist/alldigits_5\":MNISTCountDataModule} #, \\\n",
    "            #\"mnist/alldigits_large\":MNISTCountDataModule, \"mnist/alldigits_2_large\":MNISTCountDataModule,  \"mnist/alldigits_5_large\":MNISTCountDataModule,}\n",
    "#data_dict = {\"mnist/alldigits_5/\":Objects_RCNN}#, \"mnist/alldigits_2\":MNISTCountDataModule,  \"mnist/alldigits_5\":MNISTCountDataModule} #, \\\n",
    "            #\"mnist/alldigits_large\":MNISTCountDataModule\n",
    "data_dict = {\"molecules/molecules_skip\":Objects_RCNN}\n",
    "\n",
    "fold_name = \"fold\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24627f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1170b9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_mod, sweep_name in enumerate(sweep_dict.keys()):\n",
    "\n",
    "    pd_dict_acc = {\"Model\":model_names[i_mod] + \" (Acc)\"}\n",
    "    pd_dict_map = {\"Model\":model_names[i_mod] + \" (mAP)\"}\n",
    "\n",
    "\n",
    "    #model_cls = sweep_dict[sweep_names]\n",
    "    #sweep_runs = []\n",
    "    #for sweep_name in sweep_names:\n",
    "    #    sweep_runs += api.sweep(f\"{ENTITY}/object_detection/{sweep_name}\").runs\n",
    "    model_cls = sweep_dict[sweep_name]\n",
    "    sweep = api.sweep(f\"{ENTITY}/object_detection/{sweep_name}\")\n",
    "    sweep_runs = []\n",
    "    sweep_runs += api.sweep(f\"{ENTITY}/object_detection/{sweep_name}\").runs\n",
    "    print(sweep_runs)\n",
    "    for ood in [False,True]:\n",
    "\n",
    "        pd_dict_acc[\"Type\"] = \"OOD\" if ood else \"In-distribution\"\n",
    "        pd_dict_map[\"Type\"] = \"OOD\" if ood else \"In-distribution\"\n",
    "\n",
    "        \n",
    "        for data_key in data_dict.keys():\n",
    "\n",
    "            best_runs = []\n",
    "            for fold in [0,1,2,3,4]:\n",
    "                #runs_fold = [r for r in sweep_runs if (r.config.get(fold_name)==fold) and (r.config.get(\"target_data_path\")==data_key)]\n",
    "                runs_fold = [r for r in sweep_runs if (r.config.get(fold_name)==fold)]\n",
    "                runs_fold_sorted = sorted(runs_fold,key = lambda run: run.summary.get(\"restored_val_acc\"), reverse = True)\n",
    "                best_runs.append(runs_fold_sorted[0])\n",
    "\n",
    "            accuracies = []\n",
    "            mAPs = []\n",
    "            for run in best_runs:\n",
    "                fname = [f.name for f in run.files() if \"ckpt\" in f.name][0]\n",
    "                run.file(fname).download(replace = True, root = \".\")\n",
    "                model = model_cls.load_from_checkpoint(fname)\n",
    "                os.remove(fname)\n",
    "\n",
    "                hparams = dict(model.hparams)\n",
    "                hparams[\"re_train\"] = False\n",
    "                hparams[\"data_path\"]= data_key\n",
    "                dataset = data_dict[data_key](**hparams)\n",
    "                dataset.prepare_data()\n",
    "                trainer = pl.Trainer(logger = False, gpus = 1)\n",
    "\n",
    "                if ood:\n",
    "                    preds = trainer.predict(model, dataset.test_ood_dataloader())\n",
    "                else:\n",
    "                    preds = trainer.predict(model, dataset.test_dataloader())\n",
    "                \n",
    "                Y = []\n",
    "                Y_hat = []\n",
    "                map_metric = MeanAveragePrecision()\n",
    "                for pred in preds:\n",
    "                    Y += pred[\"targets\"]\n",
    "                    Y_hat += pred[\"preds\"]\n",
    "                    \n",
    "                    pred_map = [dict(boxes=pred[\"boxes\"][i],scores=pred[\"scores\"][i],labels=pred[\"preds\"][i]) for i in range(len(pred[\"targets\"]))]\n",
    "                    target_map = [dict(boxes=pred[\"boxes_true\"][i],labels=pred[\"targets\"][i]) for i in range(len(pred[\"targets\"]))]\n",
    "                    map_metric.update(pred_map,target_map)\n",
    "                \n",
    "                mAP = map_metric.compute()\n",
    "                accuracy = np.array([torch.equal(Y[i].sort()[0],Y_hat[i].sort()[0]) for i in range(len(Y))]).mean()\n",
    "                print(accuracy)\n",
    "                print(mAP)\n",
    "\n",
    "                accuracies.append(accuracy)\n",
    "                mAPs.append(mAP[\"map\"])\n",
    "\n",
    "            accuracies = np.array(accuracies)\n",
    "            acc_mu = accuracies.mean()\n",
    "            acc_std = accuracies.std()\n",
    "            \n",
    "            mAPs = np.array(mAPs)\n",
    "            map_mu = mAPs.mean()\n",
    "            map_std = mAPs.std()\n",
    "\n",
    "            acc_str = \"$ \" + str(acc_mu.round(3))+ \"\\pm\" +str(acc_std.round(3)) +\" $\"\n",
    "            map_str = \"$ \" + str(map_mu.round(3))+ \"\\pm\" +str(map_std.round(3)) +\" $\"\n",
    "\n",
    "\n",
    "            pd_dict_acc[data_key] = acc_str\n",
    "            pd_dict_acc[data_key + \" mAP\"] = map_str\n",
    "\n",
    "            print(pd_dict_acc)\n",
    "\n",
    "        df = df.append(pd_dict_acc,ignore_index =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e087ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[df.Model.str.contains(\"Acc\")].to_latex(escape = False,index= False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4964e37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
